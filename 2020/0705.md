# ARTS 20200630

## Algorithm

[5. Longest Palindromic Substring](https://leetcode-cn.com/problems/longest-palindromic-substring/)

```python
# 中心扩散法
class Solution:
    def longestPalindrome(self, s: str) -> str:
        size = len(s)
        if size < 2:
            return s

        # 至少是 1
        max_len = 1
        res = s[0]

        for i in range(size):
            palindrome_odd, odd_len = self.__center_spread(s, size, i, i)
            palindrome_even, even_len = self.__center_spread(s, size, i, i + 1)

            # 当前找到的最长回文子串
            cur_max_sub = palindrome_odd if odd_len >= even_len else palindrome_even
            if len(cur_max_sub) > max_len:
                max_len = len(cur_max_sub)
                res = cur_max_sub

        return res

    def __center_spread(self, s, size, left, right):
        """
        left = right 的时候，此时回文中心是一个字符，回文串的长度是奇数
        right = left + 1 的时候，此时回文中心是一个空隙，回文串的长度是偶数
        """
        i = left
        j = right

        while i >= 0 and j < size and s[i] == s[j]:
            i -= 1
            j += 1
        return s[i + 1:j], j - i - 1
```

## Review

原文地址 [Ball Tracking with OpenCV](https://www.pyimagesearch.com/2015/09/14/ball-tracking-with-opencv/)

本文作者使用 OpenCV 实现了一个追踪视频中彩色小球的应用，实现过程分为两步：

1. 检测一帧图片中彩色小球的位置；
2. 在视频播放过程中，对每一帧都执行第一步的操作，并绘制小球的位置。

主要代码如下：

```python
# import the necessary packages
from collections import deque
from imutils.video import VideoStream
import numpy as np
import argparse
import cv2
import imutils
import time
# construct the argument parse and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-v", "--video",
  help="path to the (optional) video file")
ap.add_argument("-b", "--buffer", type=int, default=64,
  help="max buffer size")
args = vars(ap.parse_args())
```

```python
# define the lower and upper boundaries of the "green"
# ball in the HSV color space, then initialize the
# list of tracked points
greenLower = (29, 86, 6)
greenUpper = (64, 255, 255)
pts = deque(maxlen=args["buffer"])
# if a video path was not supplied, grab the reference
# to the webcam
if not args.get("video", False):
  vs = VideoStream(src=0).start()
# otherwise, grab a reference to the video file
else:
  vs = cv2.VideoCapture(args["video"])
# allow the camera or video file to warm up
time.sleep(2.0)
```

```python
# keep looping
while True:
  # grab the current frame
  frame = vs.read()
  # handle the frame from VideoCapture or VideoStream
  frame = frame[1] if args.get("video", False) else frame
  # if we are viewing a video and we did not grab a frame,
  # then we have reached the end of the video
  if frame is None:
    break
  # resize the frame, blur it, and convert it to the HSV
  # color space
  frame = imutils.resize(frame, width=600)
  blurred = cv2.GaussianBlur(frame, (11, 11), 0)
  hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)
  # construct a mask for the color "green", then perform
  # a series of dilations and erosions to remove any small
  # blobs left in the mask
  mask = cv2.inRange(hsv, greenLower, greenUpper)
  mask = cv2.erode(mask, None, iterations=2)
  mask = cv2.dilate(mask, None, iterations=2)
```

```python
  # find contours in the mask and initialize the current
  # (x, y) center of the ball
  cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,
    cv2.CHAIN_APPROX_SIMPLE)
  cnts = imutils.grab_contours(cnts)
  center = None
  # only proceed if at least one contour was found
  if len(cnts) > 0:
    # find the largest contour in the mask, then use
    # it to compute the minimum enclosing circle and
    # centroid
    c = max(cnts, key=cv2.contourArea)
    ((x, y), radius) = cv2.minEnclosingCircle(c)
    M = cv2.moments(c)
    center = (int(M["m10"] / M["m00"]), int(M["m01"] / M["m00"]))
    # only proceed if the radius meets a minimum size
    if radius > 10:
      # draw the circle and centroid on the frame,
      # then update the list of tracked points
      cv2.circle(frame, (int(x), int(y)), int(radius),
        (0, 255, 255), 2)
      cv2.circle(frame, center, 5, (0, 0, 255), -1)
  # update the points queue
  pts.appendleft(center)
```

```python
  # loop over the set of tracked points
  for i in range(1, len(pts)):
    # if either of the tracked points are None, ignore
    # them
    if pts[i - 1] is None or pts[i] is None:
      continue
    # otherwise, compute the thickness of the line and
    # draw the connecting lines
    thickness = int(np.sqrt(args["buffer"] / float(i + 1)) * 2.5)
    cv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)
  # show the frame to our screen
  cv2.imshow("Frame", frame)
  key = cv2.waitKey(1) & 0xFF
  # if the 'q' key is pressed, stop the loop
  if key == ord("q"):
    break
# if we are not using a video file, stop the camera video stream
if not args.get("video", False):
  vs.stop()
# otherwise, release the camera
else:
  vs.release()
# close all windows
cv2.destroyAllWindows()
```

## Tips

1. Python 的 argparse 模块可以用于解析终端命令的参数。但是，当需要在 Jupyter Notebook 里运行这种脚本的时候，不能使用终端命令传入参数。此时可以把 argparse 相关代码修改为以下方式，即可正常运行该脚本。

    ```python
    import argparse
    ap = argparse.ArgumentParser()
    ap.add_argument("-v", "--video", help="path to the (optional) video file")
    ap.add_argument("-b", "--buffer", type=int, default=64, help="max buffer size")
    args = vars(ap.parse_args(args=["-v", "ball_tracking_example.mp4"]))
    ```

2. 因为一些历史原因（OpenCV 项目刚开始的时候，计算机颜色的标准定义是 BGR，后来才修改为 RGB），导致 OpenCV 内部颜色的表示方式是 BGR，所以使用 OpenCV 显示一张图片的时候，需要把 BGR 转换为 RGB，代码如下：

    ```python
    import cv2
    from matplotlib import pyplot as plt
    image = cv2.imread("./images/test_02.png")
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.show()
    ```

3. 在一个已有 Jupyter Notebook 的终端里，安装 JupyterLab 并打开浏览器，项目不会立即展示为 JupyterLab 的样式。此时把浏览器地址栏里的 `tree` 改为 `lab` 即可。官方说明如下：

    > Because JupyterLab is a server extension of the classic Jupyter Notebook server, you can launch JupyterLab by calling jupyter notebook and visiting the /lab URL. Like the classic notebook, JupyterLab provides a way for users to copy URLs that open a specific notebook or file.

## Share

一直没有系统学习过 Git。平时工作用的命令主要就是 `git add .` `git commit -m "..."` `git push` `git pull` `git status` 等。

最近遇到一个需求：本地代码库是从远程库 A clone 的，远程库 A 是从另一个远程库 B fork 的，需要把远程库 B 更新的代码 pull 到本地。 对这种需求，以前我的处理方法都是在远程库 A 上发起 pull request，把远程库 B 的更新合并到远程库 A，然后本地库再 pull 远程库 A。这个方法能解决问题，不过没有充分利用 git fork 的功能，而且太繁琐了。更专业的处理方法如下：

```bash
# 添加被 fork 的原始库 B 为 upstream
git remote add upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git
```

此时使用 `git remote -v` 查看本地库的远程状态，结果如下：

```bash
git remote -v

origin    https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch)
origin    https://github.com/YOUR_USERNAME/YOUR_FORK.git (push)
upstream  https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (fetch)
upstream  https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (push)
```

```bash
# 同步原始库 B （本地库的 upstream） 的所有分支
git fetch upstream
# 把 upstream/master 分支合并到本地库
git merge upstream/master
# push 本地库到 origin（远程库 A）的 master 分支
git push origin master
```
