# ARTS 20200628

## Algorithm

[4. Median of Two Sorted Arrays](https://leetcode-cn.com/problems/median-of-two-sorted-arrays/)

```python
from typing import List

class Solution:
    def findMedianSortedArrays(self, nums1: List[int], nums2: List[int]) -> float:
        # 中位数的值不受极值影响。所以，取两个数组的中位数做对比，根据对比结果再取两个数组的各一半（left or right）的中位数做对比，
        # 重复这个操作，直到最少一个数组为空时，停止遍历
        def getMedian(nums1: List[int], nums2: List[int], i: int, j: int, k: int) -> float:
            if i == len(nums1):
                return nums2[j + k - 1]
            elif j == len(nums2):
                return nums1[i + k - 1]
            elif k == 1:
                return min(nums1[i], nums2[j])
            else:
                i2 = min(len(nums1) - 1, int(i + k / 2 - 1))
                j2 = min(len(nums2) - 1, int(j + k / 2 - 1))
                if nums1[i2] <= nums2[j2]:
                    return getMedian(nums1, nums2, i2 + 1, j, k - i2 - 1 + i)
                else:
                    return getMedian(nums1, nums2, i, j2 + 1, k - j2 - 1 + j)

        if (len(nums1) + len(nums2)) % 2 == 0:
            return (getMedian(nums1, nums2, 0, 0, (len(nums1) + len(nums2)) // 2) + getMedian(nums1, nums2, 0, 0, (len(nums1) + len(nums2)) // 2 + 1)) / 2.0
        else:
            return getMedian(nums1, nums2, 0, 0, (len(nums1) + len(nums2)) // 2 + 1)
```

## Review

原文地址 [Bubble sheet multiple choice scanner and test grader using OMR, Python and OpenCV](https://www.pyimagesearch.com/2016/10/03/bubble-sheet-multiple-choice-scanner-and-test-grader-using-omr-python-and-opencv/)

本文作者使用 OpenCV 实现了一个简单的答题卡识别程序，实现过程分为 7 步：

1. 使用边缘检测识别出图片里的答题卡；
2. 使用透视变换校正答题卡；
3. 提取答题卡里的问题/气泡；
4. 将问题/气泡按行分组；
5. 确定每行被标记的答案；
6. 判断用户选择的答案是否正确；
7. 对每个问题重复第 6 步，得到成绩。

当然，就像作者在文章最后说的一样，这个答题卡识别程序如果想实际应用，还需要解决一些特殊问题，比如：多选、不选、全选等。

本文的主要代码如下（原文代码运行环境为 Python Shell，这里修改为 Jupyter Notebook）：

```python
# USAGE
# python test_grader.py --image images/test_01.png

# import the necessary packages
from imutils.perspective import four_point_transform
from imutils import contours
import numpy as np
import imutils
import cv2
from matplotlib import pyplot as plt

# define the answer key which maps the question number
# to the correct answer: {0: B, 1: E, 2: A, 3: D, 4: B}
ANSWER_KEY = {0: 1, 1: 4, 2: 0, 3: 3, 4: 1}

# load the image, convert it to grayscale, blur it
# slightly, then find edges
image = cv2.imread("./images/test_02.png")
plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.show()

gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
blurred = cv2.GaussianBlur(gray, (5, 5), 0)
edged = cv2.Canny(blurred, 75, 200)
plt.imshow(cv2.cvtColor(edged, cv2.COLOR_BGR2RGB))
plt.show()
```

```python
# find contours in the edge map, then initialize
# the contour that corresponds to the document
cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,
  cv2.CHAIN_APPROX_SIMPLE)
cnts = imutils.grab_contours(cnts)
docCnt = None

# ensure that at least one contour was found
if len(cnts) > 0:
  # sort the contours according to their size in
  # descending order
  cnts = sorted(cnts, key=cv2.contourArea, reverse=True)

  # loop over the sorted contours
  for c in cnts:
    # approximate the contour
    peri = cv2.arcLength(c, True)
    approx = cv2.approxPolyDP(c, 0.02 * peri, True)

    # if our approximated contour has four points,
    # then we can assume we have found the paper
    if len(approx) == 4:
      docCnt = approx
      break

# show the contour (outline) of the piece of paper
oriImg = image.copy()
cv2.drawContours(oriImg, [docCnt], -1, (0, 0, 255), 2)
plt.imshow(cv2.cvtColor(oriImg, cv2.COLOR_BGR2RGB))
plt.show()
```

```python
# apply a four point perspective transform to both the
# original image and grayscale image to obtain a top-down
# birds eye view of the paper
paper = four_point_transform(image, docCnt.reshape(4, 2))
warped = four_point_transform(gray, docCnt.reshape(4, 2))

plt.imshow(cv2.cvtColor(paper, cv2.COLOR_BGR2RGB))
plt.show()
plt.imshow(cv2.cvtColor(warped, cv2.COLOR_BGR2RGB))
plt.show()

# apply Otsu's thresholding method to binarize the warped
# piece of paper
thresh = cv2.threshold(warped, 0, 255,
  cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]

plt.imshow(cv2.cvtColor(thresh, cv2.COLOR_BGR2RGB))
plt.show()
```

```python
# find contours in the thresholded image, then initialize
# the list of contours that correspond to questions
cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,
  cv2.CHAIN_APPROX_SIMPLE)
cnts = imutils.grab_contours(cnts)
questionCnts = []

# loop over the contours
for c in cnts:
  # compute the bounding box of the contour, then use the
  # bounding box to derive the aspect ratio
  (x, y, w, h) = cv2.boundingRect(c)
  ar = w / float(h)

  # in order to label the contour as a question, region
  # should be sufficiently wide, sufficiently tall, and
  # have an aspect ratio approximately equal to 1
  if w >= 20 and h >= 20 and ar >= 0.9 and ar <= 1.1:
    questionCnts.append(c)

# show the contour (outline) of the piece of paper
oriPaper = paper.copy()
cv2.drawContours(oriPaper, questionCnts, -1, (0, 0, 255), 2)
plt.imshow(cv2.cvtColor(oriPaper, cv2.COLOR_BGR2RGB))
plt.show()
```

```python
# sort the question contours top-to-bottom, then initialize
# the total number of correct answers
questionCnts = contours.sort_contours(questionCnts,
  method="top-to-bottom")[0]
correct = 0

# each question has 5 possible answers, to loop over the
# question in batches of 5
for (q, i) in enumerate(np.arange(0, len(questionCnts), 5)):
  # sort the contours for the current question from
  # left to right, then initialize the index of the
  # bubbled answer
  cnts = contours.sort_contours(questionCnts[i:i + 5])[0]
  bubbled = None

  # loop over the sorted contours
  for (j, c) in enumerate(cnts):
    # construct a mask that reveals only the current
    # "bubble" for the question
    mask = np.zeros(thresh.shape, dtype="uint8")
    cv2.drawContours(mask, [c], -1, 255, -1)

    # apply the mask to the thresholded image, then
    # count the number of non-zero pixels in the
    # bubble area
    mask = cv2.bitwise_and(thresh, thresh, mask=mask)
    total = cv2.countNonZero(mask)

    # if the current total has a larger number of total
    # non-zero pixels, then we are examining the currently
    # bubbled-in answer
    if bubbled is None or total > bubbled[0]:
      bubbled = (total, j)

  # initialize the contour color and the index of the
  # *correct* answer
  color = (0, 0, 255)
  k = ANSWER_KEY[q]

  # check to see if the bubbled answer is correct
  if k == bubbled[1]:
    color = (0, 255, 0)
    correct += 1

  # draw the outline of the correct answer on the test
  cv2.drawContours(paper, [cnts[k]], -1, color, 3)

# grab the test taker
score = (correct / 5.0) * 100
print("[INFO] score: {:.2f}%".format(score))
cv2.putText(paper, "{:.2f}%".format(score), (10, 30),
  cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)
plt.imshow(cv2.cvtColor(paper, cv2.COLOR_BGR2RGB))
plt.show()
```

## Tips

今天的 Tips 有点多。

1. 友盟推送 iOS 提示 BadDeviceToken 导致推送失败，原因可能是：后端推送类型设置的是生产环境 production，而 App 是用 Xcode 直接 run 的，对应的推送证书类型是 develop，证书类型不匹配导致推送失败；
2. 在 iOS 项目根目录执行命令 `grep -r UIWebView .`，注意命令最后有一个 `.`，可以查看使用了 `UIWebView` 的代码文件和**静态库**，从而帮助避免因为项目里使用了 `UIWebView` 导致不能上架 App Store；
3. 在 macOS 上，不能使用隔空投送（Airdrop）发送一个以 “_” 开头的文件夹，原因待查；
4. 在 iOS 项目里，如果这样使用主线程 `dispatch_sync(dispatch_get_main_queue(), ^{});`，会造成 App 闪退。

## Share

今天分享的心得：**及时 Google**。

事情的起因是前天下午，我在把公司的一个小程序页面从 mpvue 语法转为原生小程序语法时，控制台编译报错 `Uncaught TypeError: Cannot read property 'name' of undefined`。根据这个错误提示，我开始在项目里寻找 `name` 变量，但是花了很长时间都找不到。

就在我快要放弃的时候，我想起了 Google。搜索 “小程序 + 上述错误信息”，第一条结果，点击进去，根据别人分享的内容，很快就定位并解决了问题。原来，小程序自定义组件的 properties 不能像下面这样不指定类型就直接赋初始值：

```javascript
id: ''
```

而应该改为

```javascript
id: String
```

所以，我今天的心得是：**及时 Google**。
